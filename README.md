### 쓰레드를 종료해야하는 이유
- 메모리와 커널리소스를 사용함
- CPU 사이클과 캐쉬메모리 사용
- 쓰레드가 작업을 끝냈으나 어플리케이션은 여전히 작동중이라면  
쓰레드의 리소스를 정리해야함
- 쓰레드가 오작동이라면 (응답이 없는 서버에 계속 요청을 보내는..) 중지해야함
- 어플리케이션 중지하려면 모든 쓰레드가 중지되야함
 
### 언제 우리가 쓰레드를 인터럽트 할 수 있을까?

- 스레드가 인터럽트익셉션을 throws하는 메소드를 실행하려하면
- 스레드의 코드가 인터럽트 시그널을 명백히 핸들링하려하면

### thread coordination
- 스레드가 예상 시간 안에 작업을 완료하게 만드는 법
- 특정작업을 병렬처리 
- 스레드의 실행순서 시나리오는 다양하게 존재
- 스레드 A의 출력을 스레드 B가 입력으로 받는다면? 반복문으로 스레드 A의 작업이  
종료될 때 까지 대기 그러나 이러한 대기가 스레드 B의 문맥교환시 오버헤드(CPU 사이클)가 발생함
- 스레드 A의 작업이 끝나고 입력을 받을 수 있을 때까지 sleep(대기) 하고 wake up

### Summary 
- 실행 순서에 의존해선 안된다.
- 항상 thread coordination을 사용하라
- 최악의 시나리오를 산정하고 디자인하라
- 스레드는 비상식적으로 긴 시간을 잡아먹을지도 모른다.
- 스레드 조인을 사용할 때는 시간제한을 적어라! (thread.join(*timelimit*))

### 성능 및 지연시간 최적화
- latency(지연시간) : 일련의 작업이 끝나는데 걸리는 시간. 단위시간으로 측정됨
- throughput : 주어진 period 안에 완료되는 작업들의 양 단위시간, 단위작업으로 측정됨
- task/latency(T) -> T/N  
- 이론적인 latency(T)/N의 절감 방법은 factor of N의 성능개선임
- N = ?
  - original task를 얼마나 많은 subtasks/threads로 쪼갤 수 있는가??
  - On a general purpose computer: N = number of cores
  - 하나의 스레드만 추가해도 생산성이 떨어져 성능저하와 지연시간이 늘어남  
  문맥 교환(시분할), 캐시 성능 저하(캐쉬 메모리 사용), 추가 메모리 소비(스레드에 대한 TCB?)
  - threads = cores : 모든 스레드들이 실행될 수 있고 인터럽트가 발생하지 않는 상태에서 작동할 경우 최적임  
  IO/blocking calls/sleep  etc..   
  CPU를 많이 소모하는 작업이 running중이지 않다 라는 추정
    - Hyperthreading : 코어 하나가 두 개의 스레드를 실행 물리적인 코어의 하드웨어 유닛 일부를 복제하여  
    두 스레드가 병행으로 실행되고 하드웨어 유닛 일부가 공유됨 (모든 스레드를 병렬로 실행할 수는 없음 -> 근접함)
  
  - original task를 쪼개고, result를 합산하는데에 비용/대가는 없는가?(오버헤드)
  - 어떤 작업이든 원하는 만큼의 하위 작업으로 나눌 수 있는가?

### 하나의 작업을 여러작업으로 나누었을 때(Perallelization and Aggregation) 수반되는 비용

- 하나의 작업을 여러 작업으로 분할비용
- 스레드 생성, 작업을 스레드에게 전달비용
- thread.start() (운영체제에게 위임) & 스레드 스케쥴링 비용
- 마지막 스레드가 끝나고 신호를 보낼때 까지의 시간비용
- 통합 스레드가 신호를 받아 실행하는 비용
- 하위 작업을 하나의 아티팩트로 통합하는 비용

### 어떤 작업이든 분할할 수 있는가?

- 본질적으로 병행 가능하며 하위 작업으로 쉽게 분할되는 작업
- 처음부터 싱글스레드밖에 사용할 수 없는 작업
- 부분적으로 하위 작업으로 나눌 수 있고 순차적으로 실행해야하는 작업

### Summary 
- 성능이라는 용어은 다양하게 정의되며 실제로 측정과 개선에 관심 있는 성능 메트릭은 경우  
에 따라 그때그때 정의해야함
- 멀티스레드 어플리케이션 성능 기준
  - Latency
  - Throughput
- 작업을 분할하고 병렬실행 함으로써 레이턴시 절감
- 문제를 여러 하위문제로 분할하여 (분할정복?)해결하게 된다면 속도향상을 누릴 수 있음
- 코어보다 더 많은 스레드는 블로킹 호출이 없고 단순한 계산만 하는 문제에 역효과를 낳음
- 멀티스레드로 알고리즘을 작동하는 내재비용이 있음

### +a 이미지 처리, 색 공간, 추출 및조작
- 디지털 이미지에서 **픽셀**이란 화면에 표시되는 그림의 가장 작은 요소임
- 이미지는 2차원적인 픽셀의 집합이고 다양한 방법으로 인코딩됨
- 픽셀 색상 인코딩 그룹 
  - Y'UV - 루마(밟기) 및 2개의 크로마(색상) 컴포넌트
  - RGB - 빨강, 초록, 파랑
  - HSL and HSV - 색조, 채도, 밝기/명도
  - CIE XYZ - 장비 독립적인 빨강, 초록,
- ARGB 메모리 표현

![이미지](./resources/화면%20캡처%202023-01-14%20131428.png)

### 스레드 풀링 / 처리량

- Throughput : 주어진 기간안에 완료되는 작업량, 단위 시간(초)으로 처리량을 측정
- Original Task에 대한 Latency T -> Throughput = 1(original task)/T
- Sub-task로 분할하여 정복한다면 각 task는 T/N의 시간안에 완료되고  
처리량은 N배 증가하게 됨 1/(T/N) = N/T 
- 그러나 작업을 N개로 분할 하여도 지연 시간이 줄지 않아 N/T보다 낮은 처리량을 얻을 가능성이  
농후함
- 작업이 내부적으로 연관되지 않고 별개임 따라서 각 작업을 작은 작업으로 나눠야 하는  
전처리 필요성을 없앨 수 있음
- 또한 작업은 각각 하나의 결과만 갖기 때문에 작업을 포스트 프로세스할 필요가 없음
- 완전 별개의 작업이기 때문에 다른 작업의 완료를 위해 그 작업이 끝나길 기다리지 않아도 됨
- 스레드 풀링 / 논블로킹 대기열로 최적의 처리량을 얻을 수 있음

### 스레드 풀링
- 스레드를 생성하면 풀에 쌓임 request(미래의 작업)이 요청되면 스레드 풀에 있는 스레드를 사용
- 작업이 대기열을 통해 스레드별로 분배
- 스레드는 이용 가능할 때마다 대기열을 통해 작업을 받음
- 모든 스레드가 바쁘면 대기열에 머무르고 최대 처리량과 리소스의 최대 사용률을 얻을 수 있음
- 스레드풀 구현은 구현할만한 가치가 있음 (낮은 오버헤드, 효율적인 대기열을 구현)
- 고정 스레드 풀 실행기
  - int numberOfThreads = 4;
  - Excutor executor = Executors.newFiexdThreadPool(numberOfThreads);
  - Runnable task = ...;
  - executor.execute(task);
  
### Summary

- 각각의 작업을 스레드에 제공함으로써, 처리량을 N배 향상시킬 수 있다
- 고정스레드풀을 사용하면 고정된 스레드수를 유지하면서 스레드 재생성 필요성을 제거가능
- 상당한 성능향상(N배 처리량)

### HTTP 서버 && throughput